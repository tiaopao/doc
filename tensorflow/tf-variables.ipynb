{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Variables （变量）\n",
    "  \n",
    "  \n",
    "## tf.Variable是一个类（class)\n",
    " - 在run调用过程中， 变量维护图（graph）中的状态，可以创建一个Variable类的实例并增加到图中（graph)\n",
    " - Variable构造函数要求：变量的初始化值（任何type和shape的Tensor）, 在实例创建完成之后，Variable的type和shape固定不变，但变量的值可通过赋值方法修改\n",
    " - 常用于保存网络中需要学习的参数\n",
    " - 在使用变量值的操作中，必须先初始化变量\n",
    " - 变量初始化方法：\n",
    "  -  sess.run(w.initializer)  # Run the variable initializer.\n",
    "  - 初始化所有变量：使用global_variables_initializer()增加一个Op到图中\n",
    "    \n",
    "\n",
    "## tf.constant 与 tf.Variable的区别\n",
    " - tf.constant 是一个操作（op）\n",
    " - tf.Variable 是一个包含许多操作（ops)的类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Variable类构造函数 (tf.Variable)\n",
    "__init__(\n",
    "    initial_value=None,\n",
    "    trainable=True,\n",
    "    collections=None,\n",
    "    validate_shape=True,\n",
    "    caching_device=None,\n",
    "    name=None,\n",
    "    variable_def=None,\n",
    "    dtype=None,\n",
    "    expected_shape=None,\n",
    "    import_scope=None,\n",
    "    constraint=None\n",
    ")\n",
    "\n",
    "- 此构造函数把类实例（变量）增加到集合**GraphKeys.GLOBAL_VARIABLES** （可通过函数：global_variables() 获取）\n",
    "- 若trainable=True, 变量也被增加到集合 **GraphKeys.TRAINABLE_VARIABLES** （可通过函数：trainable_variables() 获取）\n",
    "\n",
    "## tf.Variable的常用操作（ops）\n",
    " - x = tf.Variable(...)\n",
    " - x.initializer　　　# init op\n",
    " - x.value()　　　　# read op\n",
    " - x.assign(...)　　　# write op\n",
    " - x.assign_add(...)　# and more\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.get_variable\n",
    "tf.get_variable(\n",
    "    name,\n",
    "    shape=None,\n",
    "    dtype=None,\n",
    "    initializer=None,\n",
    "    regularizer=None,\n",
    "    trainable=True,\n",
    "    collections=None,\n",
    "    caching_device=None,\n",
    "    partitioner=None,\n",
    "    validate_shape=True,\n",
    "    use_resource=None,\n",
    "    custom_getter=None,\n",
    "    constraint=None\n",
    ")\n",
    " - 使用这些参数获取一个已经存在的变量或创建一个新的变量；\n",
    " - 可根据 name 值，返回该变量，如果该 name 不存在的话，则会进行创建；\n",
    " - 与tf.variable_scope()配合使用, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Variable与tf.get_variable的区别\n",
    " - 都用于创建变量\n",
    " - tf.Variable() 每次调用都会创建新的变量，在变量名重复的时候不会报错，而是会自动创建新的变量，只是后缀加上 $_1, _2$ 类似的用以区别。通常 lr 或 global step 之类的辅助变量会使用它来创建。\n",
    " - tf.get_variable() 则主要用于网络的权值设置，它可以实现权值共享，在多 GPU 的并行计算的时候使用较多，其实通过 get 的前缀就可以很好看出它们的区别，它一定是和tf.variable_scope()共同使用的，不然二者就没有太大的区别了。\n",
    " - 如果在 tf.name_scope() 环境下分别使用 tf.get_variable() 和 tf.Variable()，两者的主要区别在于:\n",
    "  - tf.get_variable() 创建的变量名不受 name_scope 的影响；\n",
    "  - tf.get_variable() 创建的变量名受name_scope的影响，在同一个name_scope中，name 属性值不可以相同；tf.Variable() 创建变量时，name 属性值允许重复（底层实现时，会自动引入别名机制）\n",
    " - tf.get_variable() 与 tf.Variable() 相比，多了一个 initilizer （初始化子）可选参数； \n",
    " - tf.Variable() 对应地多了一个 initial_value 关键字参数，也即对于 tf.Variable 创建变量的方式，必须显式初始化；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar:0 2\n",
      "matrix:0 [[1 2 3]\n",
      " [4 5 6]]\n",
      "a_name_scope1/V1:0 [1 2 3]\n",
      "a_name_scope1/V1_1:0 [4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.name_scope('a_name_scope1'):\n",
    "    s = tf.get_variable('scalar', initializer=tf.constant(2))\n",
    "    #s1 = tf.get_variable('scalar', initializer=tf.constant(3))\n",
    "    m = tf.get_variable('matrix', initializer=tf.constant([[1,2,3],[4,5,6]]))\n",
    "    w = tf.get_variable('big_matrix', shape=(784,10), initializer=tf.zeros_initializer())\n",
    "    \n",
    "    V1 = tf.Variable([1,2,3], name=\"V1\")\n",
    "    V2 = tf.Variable([4,5,6], name=\"V1\")\n",
    "    \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())  # init all the variables at once\n",
    "    sess.run(tf.variables_initializer([s,m]))  # init only a subset of variables\n",
    "    print(s.name, sess.run(s))\n",
    "    print(m.name, sess.run(m))\n",
    "    #print(w.name, sess.run(w))\n",
    "    sess.run(V1.initializer)\n",
    "    sess.run(V2.initializer)\n",
    "    print(V1.name, sess.run(V1))\n",
    "    print(V2.name, sess.run(V2))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_3:0' shape=(700, 10) dtype=float32_ref>\n",
      "Variable_3:0 [[-0.43859518  0.2781226   1.319621   ...  1.0081005   0.182192\n",
      "  -0.22677897]\n",
      " [-0.89711714  0.11727114 -1.5676941  ... -1.1863619  -0.90292066\n",
      "  -0.18442577]\n",
      " [-1.4942753   0.19102633 -1.6815547  ...  0.32588097 -0.92992514\n",
      "   0.09963764]\n",
      " ...\n",
      " [ 0.2552708   0.45992097  1.5574944  ... -0.10122806 -0.43588033\n",
      "   0.40415704]\n",
      " [ 1.6478871  -0.64953315  0.33808044 ...  0.18847999  0.7887517\n",
      "   0.8116403 ]\n",
      " [-1.620304   -1.4811673   1.4582502  ... -0.29823163  1.8483113\n",
      "   0.04658151]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "W = tf.Variable(tf.truncated_normal([700, 10]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(W)\n",
    "    #print(sess.run(W))\n",
    "    print(W.name, W.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Variable.assign() 是一个操作，必须在Session中被执行\n",
    " - 变量的Var.eval()操作类似sess.run(Var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable_9:0 1000\n",
      "var_1:0 6\n",
      "var_1:0 18\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "W = tf.Variable(10)\n",
    "#W.assign(1000)  # create an assign op, the op needs to be executed in a session\n",
    "assign_op = W.assign(1000)\n",
    "\n",
    "var = tf.Variable(2, name='var')\n",
    "var_times_two = var.assign(3 * var)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(assign_op)\n",
    "    print(W.name, W.eval())\n",
    "    \n",
    "    sess.run(var.initializer)\n",
    "    sess.run(var_times_two)\n",
    "    print(var.name, var.eval())　　#　var.eval()类似sess.run(var)\n",
    "    \n",
    "    sess.run(var_times_two)\n",
    "    print(var.name, var.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.Variable.assign_add和tf.Variable.assign_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "var = tf.Variable(10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var.initializer)\n",
    "    print(sess.run(var.assign_add(5)))\n",
    "    print(sess.run(var.assign_sub(6)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 每个Session维护自己的变量copy\n",
    " - Session类似Linux中的进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First:\n",
      "15\n",
      "9\n",
      "Second\n",
      "20\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "var = tf.Variable(10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var.initializer)\n",
    "    print('First:')\n",
    "    print(sess.run(var.assign_add(5)))\n",
    "    print(sess.run(var.assign_sub(6)))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(var.initializer)\n",
    "    print('Second')\n",
    "    print(sess.run(var.assign_add(10)))\n",
    "    print(sess.run(var.assign_sub(5)))   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF程序由两个阶段组成\n",
    " 1）组装一个图（Assemble a graph）  \n",
    " 2）使用Session执行图中的操作（Node）\n",
    " - 因为在定义计算时无法提供用于计算的数据，则可使用tf.placeholder\n",
    " - **tf.placeholder(dtype, shape=None, name=None)**\n",
    " - **placeholder是 一 个有效的操作（在图中的一个Node）**\n",
    " - shape: 列表[]中一个数字，表示一个向量，向量元素为列表中的数字；2个数字表示一个矩阵，前面的表示行数，后面的表示列数；3个数字表示三维数组\n",
    " - shape=None: 表示它可接受任何shape的tensor作为placeholder的输入值，但是也为调试带来了困难\n",
    " - 可以feed_dict任何可以传入的tensor, 判断tensor是否可传入的方式：\n",
    "  **tf.Graph.is_feedable(tensor)**\n",
    " - placeholder：表明必须被传入数据\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.  7. 11.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# create a placeholder for a vector with 3 elements, type tf.float32\n",
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "b = tf.constant([3,2,1], tf.float32)\n",
    "c = a + b  # short for tf.add(a,b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     print(sess.run(c, feed_dict={a:[4,5,6]}))  # the tensor a is the key, not the string 'a'\n",
    "    print(sess.run(c, {a:[4,5,10]}))  # the tensor a is the key, not the string 'a'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把值传入TF操作\n",
    " - 在测试一个大的Graph的一部分子图时，通过传入默认值很有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# create operations, tensor, etc\n",
    "a = tf.add(2, 5)\n",
    "b = tf.multiply(a, 5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # compute the value of b given a is 15\n",
    "    print(sess.run(b, feed_dict={a:30}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Loading vs. Lazy Loading\n",
    " - Normal Loading: 在Session外创建或初始化对象，在Graph中只有一个Node\n",
    " - Lazy Loading: 在Session内创建或初始化对象，在Graph中执行一次就创建一个Node，执行多次就有多个Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# normal loading\n",
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(15, name='y')\n",
    "z = tf.add(x,y)\n",
    "\n",
    "writer = tf.summary.FileWriter('/home/ai/work/log/graphs/', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for var in range(10):\n",
    "        print(sess.run(z))\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# lazy loading\n",
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(15, name='y')\n",
    "#z = tf.add(x,y)\n",
    "\n",
    "writer = tf.summary.FileWriter('/home/ai/work/log/graphs', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for var in range(10):\n",
    "        print(sess.run(tf.add(x,y)))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.constant 和tf.Variable\n",
    " - 常量值被存储在图定义中\n",
    " - Session分配内存存储变量的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1874919424\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = 2\n",
    "y = 8\n",
    "add_op = tf.add(x,y,name='add_op')\n",
    "mul_op = tf.multiply(x,y,name='add_op')\n",
    "useless = tf.multiply(x, add_op, name='useless')\n",
    "pow_op = tf.pow(add_op, mul_op, name='power_op')\n",
    "writer = tf.summary.FileWriter('/home/ai/work/log/graphs', tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run(pow_op)\n",
    "    print(z)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a:0\", shape=(5,), dtype=int32)\n",
      "140208805686128\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1, 2, 3, 4, 5], name='a')\n",
    "print(a)\n",
    "print(id(a))  # id()获取Tensor的地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
